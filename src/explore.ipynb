{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp5KzVc7yREH"
      },
      "source": [
        "# Image Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqdQZgZnfSvg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "import zipfile\n",
        "import random\n",
        "import pickle\n",
        "import shutil\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Upload and processing the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDreoDSRfSvk"
      },
      "outputs": [],
      "source": [
        "url = \"https://storage.googleapis.com/datascience-materials/dogs-vs-cats.zip\"\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "    z.extractall(\"../src/dogs-vs-cats\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxs3x0h8fSvl"
      },
      "outputs": [],
      "source": [
        "images_folder = \"../src/dogs-vs-cats/dogs-vs-cats/train\"\n",
        "source_folder = \"../data/processed\"\n",
        "cats_folder = \"../data/processed/cats\"\n",
        "dogs_folder = \"../data/processed/dogs\"\n",
        "\n",
        "# Crear carpetas si no existen\n",
        "os.makedirs(source_folder, exist_ok=True)\n",
        "os.makedirs(cats_folder, exist_ok=True)\n",
        "os.makedirs(dogs_folder, exist_ok=True)\n",
        "\n",
        "# Contadores para limitar 100 por clase\n",
        "cat_count = 0\n",
        "dog_count = 0\n",
        "max_images = 250  # máximo por clase\n",
        "\n",
        "for filename in os.listdir(images_folder):\n",
        "    file_path = os.path.join(images_folder, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        nombre = filename.lower()\n",
        "        if nombre.startswith(\"cat\") and cat_count < max_images:\n",
        "            shutil.copy(file_path, os.path.join(cats_folder, filename))\n",
        "            cat_count += 1\n",
        "        elif nombre.startswith(\"dog\") and dog_count < max_images:\n",
        "            shutil.copy(file_path, os.path.join(dogs_folder, filename))\n",
        "            dog_count += 1\n",
        "\n",
        "        # Romper el loop si ya tenemos 100 de cada clase\n",
        "        if cat_count >= max_images and dog_count >= max_images:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PETv4QTTfSvn"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_images(data_dir, target_size=(224, 224)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for label in os.listdir(data_dir):\n",
        "        label_dir = os.path.join(data_dir, label)\n",
        "        if os.path.isdir(label_dir):\n",
        "            for filename in os.listdir(label_dir):\n",
        "                img_path = os.path.join(label_dir, filename)\n",
        "                try:\n",
        "                    img = image.load_img(img_path, target_size=target_size)\n",
        "                    img_array = image.img_to_array(img)\n",
        "                    img_array /= 255.0  # Normalizar los valores de píxeles\n",
        "                    images.append(img_array)\n",
        "                    # Asigna la etiqueta 0 para \"Cat\" y 1 para \"Dog\"\n",
        "                    if label == \"cats\":\n",
        "                        labels.append(0)\n",
        "                    elif label == \"dogs\":\n",
        "                        labels.append(1)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error cargando la imagen {img_path}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "images, labels = load_and_preprocess_images(\"../data/processed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Split Train & Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "KKPYWqq7fSvo"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(images,labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aJxGodofSvo"
      },
      "outputs": [],
      "source": [
        "source_dir = \"../data/processed\"\n",
        "\n",
        "train_dir = \"../data/train\"\n",
        "test_dir = \"../data/test\"\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "classes = [\"cats\", \"dogs\"]\n",
        "\n",
        "for cls in classes:\n",
        "    cls_path = os.path.join(source_dir, cls)\n",
        "    files = os.listdir(cls_path)\n",
        "\n",
        "    train_files, test_files = train_test_split(files, test_size=0.2, random_state=42)\n",
        "    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, cls), exist_ok=True)\n",
        "\n",
        "    for f in train_files:\n",
        "        shutil.copy(os.path.join(cls_path, f), os.path.join(train_dir, cls, f))\n",
        "\n",
        "    for f in test_files:\n",
        "        shutil.copy(os.path.join(cls_path, f), os.path.join(test_dir, cls, f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X1JrswWfSvq",
        "outputId": "8fe209b4-6239-4c03-a812-9e97caa69965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "{'cats': 0, 'dogs': 1}\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    \"../data/train\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    \"../data/test\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(train_data.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgy4wEpifSvr",
        "outputId": "0c409bd8-0017-4684-9132-d8eea2ee78a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape = (224,224,3), filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = \"same\", activation = \"relu\"))\n",
        "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
        "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
        "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
        "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
        "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 4096,activation = \"relu\"))\n",
        "model.add(Dense(units = 4096,activation = \"relu\"))\n",
        "model.add(Dense(units = 2, activation = \"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAAjhM1QfSvs"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = \"adam\", loss = CategoricalCrossentropy(from_logits = True), metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckThj6Y2fSvt",
        "outputId": "40b39956-c38e-448f-c6b9-ae78bdf4d30b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/nn.py:717: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2151s\u001b[0m 85s/step - accuracy: 0.4645 - loss: 0.7010 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 2/2\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2121s\u001b[0m 84s/step - accuracy: 0.5242 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6933\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c7d92e344a0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_data,\n",
        "    epochs=2,\n",
        "    validation_data=test_data\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKTeGxH3fSvt"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Save the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIjrl9rZfSvu",
        "outputId": "71a640c6-2889-4872-b6a3-520d20def993"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('image-classifier-model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWxVS0vKy9wv",
        "outputId": "07b6dc27-d7c9-45ac-97d2-89f042057de3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Selected image: dog.6647.jpg (from dogs)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805ms/step\n",
            "Predicted: It's a Dog (confidence: 0.5004)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the trained model \n",
        "modelo = load_model(\"image-classifier-model.h5\")\n",
        "\n",
        "# Test directories\n",
        "test_dir = \"../data/test\"\n",
        "\n",
        "# Pick a random image\n",
        "random_class = random.choice([\"cats\", \"dogs\"])\n",
        "class_dir = os.path.join(test_dir, random_class)\n",
        "\n",
        "random_image = random.choice(os.listdir(class_dir))\n",
        "image_path = os.path.join(class_dir, random_image)\n",
        "\n",
        "print(f\" Selected image: {random_image} (from {random_class})\")\n",
        "\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict\n",
        "prediction = modelo.predict(img_array)[0][0]\n",
        "\n",
        "if prediction < 0.5:\n",
        "    print(f\"Predicted: It's a Cat (confidence: {1 - prediction:.4f})\")\n",
        "else:\n",
        "    print(f\"Predicted: It's a Dog (confidence: {prediction:.4f})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2 (default, Dec 21 2020, 15:06:04) \n[Clang 12.0.0 (clang-1200.0.32.29)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
